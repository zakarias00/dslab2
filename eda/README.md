# eda — Exploratory Data Analysis

This folder contains exploratory data analysis (EDA) notebooks and scripts for the project. Its purpose is to inspect, clean, visualize, and summarize the dataset(s) used in this repository and to produce figures, tables, and intermediate artifacts that inform modeling and reporting decisions.

## Structure / Contents
- notebooks/ or .ipynb files — Jupyter notebooks used for interactive exploration and plotting.
- scripts/ — standalone Python scripts for cleaning, preprocessing, or generating figures.
- data/ (or a pointer to the repository's data folder) — small sample datasets or derived datasets produced by EDA (do not store sensitive/large raw data here).
- figures/ — exported images and plots generated by notebooks.
- README.md — this file.

(If you'd like, I can list the exact files in this folder and update the "Structure" section for accuracy.)

## Goals
- Inspect data quality and completeness
- Identify missing values, outliers, and data distributions
- Generate exploratory visualizations for features and relationships
- Create and document data-processing steps that will be reused by modeling pipelines
- Produce reproducible notebooks and shareable figures for reports

## Quick start / Reproducibility
1. Create a Python environment (recommended):
   - conda:
     - `conda create -n eda-env python=3.9`
     - `conda activate eda-env`
   - or venv:
     - `python -m venv .venv`
     - `source .venv/bin/activate` (macOS / Linux) or `.venv\Scripts\activate` (Windows)

2. Install dependencies:
   - If a top-level `requirements.txt` or an `environment.yml` exists in the repo, use that:
     - `pip install -r requirements.txt`
     - or `conda env update -f environment.yml`
   - Typical packages used in EDA:
     - `pandas`, `numpy`, `matplotlib`, `seaborn`, `plotly`, `scikit-learn`, `notebook`, `jupyterlab`

3. Open notebooks:
   - `jupyter lab` or `jupyter notebook` and open the notebooks in this folder.
   - To run a notebook headlessly and export results (useful for CI):
     - `jupyter nbconvert --to html --execute path/to/notebook.ipynb`

## Data handling
- Do not commit large raw data or sensitive information to this folder or the repository.
- If raw data is required to run the notebooks, indicate where it should be placed (e.g., `../data/raw/`) or provide a script that downloads/creates a small sample for reproducibility.
- Document any data sources and licensing in the top-level repository README or a DATA.md file.

## Outputs
- Figures saved to `figures/` (recommended formats: `.png`, `.svg`, `.pdf`)
- Derived small datasets saved to `data/` with clear naming and a README describing each derived file

## Notebook hygiene / best practices
- Keep long-running computations in scripts; use notebooks mainly for high-level exploration and visualization.
- Use clear headings, descriptive captions for figures, and textual explanations of findings.
- Parameterize notebooks where useful (papermill) to allow reproducible runs across subsets or configurations.
